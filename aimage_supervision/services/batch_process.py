import asyncio
import json
import os
import tempfile
import time
import uuid
from datetime import datetime, timezone
from typing import Any, Dict, List, Literal, Optional, Tuple, cast
from uuid import UUID

import httpx
from google import genai
from google.genai import types
from PIL import Image
from pydantic import BaseModel, Field
from tortoise.exceptions import DoesNotExist, IntegrityError
from tortoise.expressions import Q
from tortoise.transactions import in_transaction

from aimage_supervision.clients.aws_s3 import (
    download_file_content_from_s3, download_file_content_from_s3_sync,
    download_image_from_s3, download_video_from_s3, get_s3_url_from_path)
from aimage_supervision.enums import (AiReviewMode, AiReviewProcessingStatus,
                                      SubtaskType)
from aimage_supervision.models import (AiReview, AiReviewFindingEntry,
                                       Character, ReviewPointDefinition,
                                       ReviewPointDefinitionVersion, Subtask,
                                       User)
from aimage_supervision.prompts.review_point_prompts import (
    copyright_review_prompt, ng_review_prompt, visual_review_prompt)
from aimage_supervision.schemas import AiDetectedElement, AiDetectedElements
from aimage_supervision.schemas import AiReview as AiReviewSchema
from aimage_supervision.schemas import \
    AiReviewFindingEntry as AiReviewFindingEntrySchema
from aimage_supervision.schemas import (AiReviewFindingEntryInDB, AiReviewInDB,
                                        FindingArea)
from aimage_supervision.schemas import \
    ReviewPointDefinition as ReviewPointDefinitionSchema
from aimage_supervision.schemas import (ReviewPointDefinitionCreate,
                                        ReviewPointDefinitionVersionBase,
                                        ReviewPointDefinitionVersionInDB,
                                        Severity)
from aimage_supervision.services.ai_review_service import \
    initiate_ai_review_for_subtask
from aimage_supervision.settings import MAX_CONCURRENT, logger


async def batch_initiate_cr_check_parallel(
    subtasks: List[Subtask],
    initiated_by_user_id: UUID,
    max_concurrent: Optional[int] = None,
    mode: AiReviewMode = AiReviewMode.QUALITY
) -> None:
    """
    å¹¶è¡Œå¤„ç†å¤šä¸ªå­ä»»åŠ¡çš„CRæ£€æŸ¥ã€‚

    è¿™ä¸ªå‡½æ•°è®¾è®¡ä¸ºåå°ä»»åŠ¡ä½¿ç”¨ï¼Œæ‰€æœ‰ç»“æœé€šè¿‡æ—¥å¿—è®°å½•ã€‚
    ç”±äºæ˜¯åå°ä»»åŠ¡ï¼Œè¿”å›å€¼ä¼šè¢«FastAPIæ¡†æ¶ä¸¢å¼ƒã€‚

    Args:
        subtasks: éœ€è¦å¤„ç†çš„å­ä»»åŠ¡åˆ—è¡¨
        initiated_by_user_id: å‘èµ·ç”¨æˆ·çš„ID
        max_concurrent: æœ€å¤§å¹¶å‘æ•°é‡ï¼Œé»˜è®¤ä» settings ä¸­è¯»å–

    Returns:
        None: åå°ä»»åŠ¡ä¸éœ€è¦è¿”å›å€¼ï¼Œæ‰€æœ‰ä¿¡æ¯é€šè¿‡æ—¥å¿—è¾“å‡º
    """

    batch_start_time = time.time()
    batch_id = str(uuid.uuid4())[:8]  # ä¸ºè¿™ä¸ªæ‰¹æ¬¡åˆ›å»ºä¸€ä¸ªçŸ­IDç”¨äºæ—¥å¿—è¿½è¸ª

    # ========== æ•°æ®åº“è®°å½• - å¼€å§‹ ==========
    from datetime import datetime, timezone

    from aimage_supervision.enums import BatchJobStatus
    from aimage_supervision.models import BatchProcessJob, User

    # è·å–é¡¹ç›®IDï¼ˆä»ç¬¬ä¸€ä¸ªsubtaskè·å–ï¼Œå‡è®¾æ‰€æœ‰subtaskå±äºåŒä¸€ä¸ªé¡¹ç›®ï¼‰
    project_id = None
    if subtasks:
        first_subtask = subtasks[0]
        await first_subtask.fetch_related('task__project')
        project_id = first_subtask.task.project.id if first_subtask.task and first_subtask.task.project else None

    # åˆ›å»ºæ‰¹å¤„ç†ä»»åŠ¡è®°å½•
    batch_job = await BatchProcessJob.create(
        batch_id=batch_id,
        job_name=f"AI_CR_Check_{batch_id}_{len(subtasks)}tasks",
        job_type="ai_review_cr_check",
        status=BatchJobStatus.RUNNING,
        created_by_id=initiated_by_user_id,
        project_id=project_id,
        total_items=len(subtasks),
        processed_items=0,
        successful_items=0,
        failed_items=0,
        started_at=datetime.now(timezone.utc),
        max_concurrent=max_concurrent if max_concurrent is not None else MAX_CONCURRENT,
        parameters={
            "subtask_ids": [str(subtask.id) for subtask in subtasks],
            "max_concurrent": max_concurrent if max_concurrent is not None else MAX_CONCURRENT,
            "initiated_by_user_id": str(initiated_by_user_id)
        }
    )

    logger.info(f"ğŸ—„ï¸ [æ‰¹æ¬¡ {batch_id}] åˆ›å»ºæ•°æ®åº“è®°å½•: {batch_job.id}")

    # åˆ›å»ºä¿¡å·é‡æ¥æ§åˆ¶å¹¶å‘æ•°é‡
    if max_concurrent is None:
        max_concurrent = MAX_CONCURRENT
    semaphore = asyncio.Semaphore(max_concurrent)

    async def process_single_subtask_with_limit(subtask: Subtask, task_index: int) -> Dict[str, Any]:
        """å¸¦å¹¶å‘é™åˆ¶çš„å•ä¸ªå­ä»»åŠ¡å¤„ç†"""
        subtask_short_id = str(subtask.id)[:8]

        # ç­‰å¾…è·å–ä¿¡å·é‡çš„æ—¶é—´
        wait_start_time = time.time()

        async with semaphore:
            wait_time = time.time() - wait_start_time
            actual_start_time = time.time()
            try:
                result = await initiate_ai_review_for_subtask(
                    subtask_id=subtask.id,
                    initiated_by_user_id=initiated_by_user_id,
                    cr_check=True,
                    mode=mode
                )

                processing_time = time.time() - actual_start_time
                total_time_from_batch_start = time.time() - batch_start_time
                # è®¡ç®—æ•´ä½“ä¸¥é‡ç¨‹åº¦
                overall_severity = "safe"  # é»˜è®¤å€¼
                if result.findings:
                    # è·å–æ‰€æœ‰findingsçš„severity
                    severities = [
                        finding.severity for finding in result.findings]
                    # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åºï¼šrisk > alert > safe
                    severity_order = {"risk": 3, "alert": 2, "safe": 1,
                                      # å‘åå…¼å®¹æ—§å€¼
                                      "high": 3, "medium": 2, "low": 1}
                    max_severity_value = max(
                        severities, key=lambda s: severity_order.get(s, 0))
                    overall_severity = max_severity_value
                return {
                    "subtask_id": str(subtask.id),
                    "subtask_short_id": subtask_short_id,
                    "task_index": task_index + 1,
                    "status": "success",
                    "ai_review_id": str(result.id),
                    "findings_count": len(result.findings) if result.findings else 0,
                    "severity": overall_severity,
                    "wait_time": wait_time,
                    "processing_time": processing_time,
                    "total_time_from_batch_start": total_time_from_batch_start,
                    "start_timestamp": actual_start_time,
                    "end_timestamp": time.time(),
                    "error": None
                }

            except Exception as e:
                processing_time = time.time() - actual_start_time
                total_time_from_batch_start = time.time() - batch_start_time
                error_msg = f"å¤„ç†å­ä»»åŠ¡ {subtask.id} æ—¶å‡ºé”™: {str(e)}"
                return {
                    "subtask_id": str(subtask.id),
                    "subtask_short_id": subtask_short_id,
                    "task_index": task_index + 1,
                    "status": "error",
                    "ai_review_id": None,
                    "findings_count": 0,
                    "severity": None,
                    "wait_time": wait_time,
                    "processing_time": processing_time,
                    "total_time_from_batch_start": total_time_from_batch_start,
                    "start_timestamp": actual_start_time,
                    "end_timestamp": time.time(),
                    "error": error_msg
                }

    tasks = [process_single_subtask_with_limit(
        subtask, i) for i, subtask in enumerate(subtasks)]

    # è®°å½•ä»»åŠ¡åˆ›å»ºå®Œæˆæ—¶é—´
    tasks_created_time = time.time()

    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼Œä½¿ç”¨ return_exceptions=True ç¡®ä¿å•ä¸ªä»»åŠ¡å¤±è´¥ä¸å½±å“å…¶ä»–ä»»åŠ¡
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # è®°å½•æ‰€æœ‰ä»»åŠ¡å®Œæˆæ—¶é—´
    all_tasks_completed_time = time.time()

    # å¤„ç†å¯èƒ½çš„å¼‚å¸¸ç»“æœ
    processed_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            # å¦‚æœ gather æœ¬èº«å‡ºç°å¼‚å¸¸
            logger.error(f"ğŸ”¥ [æ‰¹æ¬¡ {batch_id}] ä»»åŠ¡ {i+1} gatherå¼‚å¸¸: {str(result)}")
            processed_results.append({
                "subtask_id": str(subtasks[i].id),
                "subtask_short_id": str(subtasks[i].id)[:8],
                "task_index": i + 1,
                "status": "error",
                "ai_review_id": None,
                "findings_count": 0,
                "severity": None,
                "wait_time": 0,
                "processing_time": 0,
                "total_time_from_batch_start": all_tasks_completed_time - batch_start_time,
                "start_timestamp": batch_start_time,
                "end_timestamp": all_tasks_completed_time,
                "error": f"æ‰¹é‡å¤„ç†å¼‚å¸¸: {str(result)}"
            })
        else:
            processed_results.append(result)  # type: ignore[arg-type]

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_time = all_tasks_completed_time - batch_start_time
    successful_count = sum(
        1 for r in processed_results if r["status"] == "success")
    failed_count = len(processed_results) - successful_count

    # åˆ›å»º subtask_id åˆ° severity çš„æ˜ å°„å­—å…¸
    subtask_severity_map = {}
    for result in processed_results:
        if result["status"] == "success" and result["severity"]:
            subtask_severity_map[str(result["subtask_id"])
                                 ] = result["severity"]
        else:
            subtask_severity_map[str(result["subtask_id"])] = "failed"

    # è®¡ç®—å¹¶è¡Œæ•ˆç‡
    if successful_count > 0:
        avg_processing_time = sum(r["processing_time"] for r in processed_results if r["status"]
                                  == "success") / successful_count
        theoretical_serial_time = avg_processing_time * len(subtasks)
        parallel_efficiency = (theoretical_serial_time /
                               total_time) * 100 if total_time > 0 else 0

    # ========== æ•°æ®åº“è®°å½• - ç»“æŸ ==========
    try:
        # æ›´æ–°æ‰¹å¤„ç†ä»»åŠ¡è®°å½•
        if successful_count == 0 and failed_count > 0:
            # å…¨éƒ¨å¤±è´¥
            batch_job.status = BatchJobStatus.FAILED
        else:
            # æœ‰æˆåŠŸçš„ä»»åŠ¡ï¼ˆå¯èƒ½ä¹Ÿæœ‰å¤±è´¥çš„ï¼‰
            batch_job.status = BatchJobStatus.COMPLETED
        batch_job.processed_items = len(processed_results)
        batch_job.successful_items = successful_count
        batch_job.failed_items = failed_count
        batch_job.completed_at = datetime.now(timezone.utc)

        # ä¿å­˜è¯¦ç»†ç»“æœ
        batch_job.results = {
            "summary": {
                "total_tasks": len(subtasks),
                "successful_count": successful_count,
                "failed_count": failed_count,
                "total_time_seconds": total_time,
                "parallel_efficiency_percent": parallel_efficiency if successful_count > 0 else 0,
                "avg_processing_time_seconds": avg_processing_time if successful_count > 0 else 0,
                "severity_counts": subtask_severity_map
            },
            "performance_metrics": {
                "batch_start_time": batch_start_time,
                "tasks_created_time": tasks_created_time,
                "all_tasks_completed_time": all_tasks_completed_time,
                "theoretical_serial_time": theoretical_serial_time if successful_count > 0 else 0
            }
        }

        await batch_job.save()

        logger.info(
            f"ğŸ—„ï¸ [æ‰¹æ¬¡ {batch_id}] æ›´æ–°æ•°æ®åº“è®°å½•å®Œæˆ: çŠ¶æ€={batch_job.status.value}, æˆåŠŸ={successful_count}/{len(subtasks)}")

    except Exception as db_error:
        logger.error(f"ğŸ—„ï¸ [æ‰¹æ¬¡ {batch_id}] æ›´æ–°æ•°æ®åº“è®°å½•å¤±è´¥: {str(db_error)}")
        # å³ä½¿æ•°æ®åº“æ›´æ–°å¤±è´¥ï¼Œä¹Ÿä¸å½±å“ä¸»è¦ä»»åŠ¡çš„å®Œæˆ


async def expand_review_sets_to_rpd_ids(project_id: UUID, review_set_ids: Optional[List[UUID]] = None) -> List[UUID]:
    """
    å°† Review Set IDs å±•å¼€ä¸º RPD IDs

    Args:
        project_id: é¡¹ç›®ID
        review_set_ids: Review Set IDs åˆ—è¡¨

    Returns:
        å±•å¼€åçš„ RPD IDs åˆ—è¡¨
    """
    if not review_set_ids:
        return []

    try:
        from aimage_supervision.models import ReviewSet

        # æŸ¥è¯¢æ‰€æœ‰æŒ‡å®šçš„Review Setsï¼Œå¹¶é¢„åŠ è½½å…³è”çš„RPDs
        review_sets = await ReviewSet.filter(
            id__in=review_set_ids,
            project_id=project_id,
        ).prefetch_related('rpds')

        # æ”¶é›†æ‰€æœ‰RPD IDs
        rpd_ids = []
        for review_set in review_sets:
            for rpd in review_set.rpds:
                rpd_ids.append(rpd.id)

        # å»é‡å¹¶è¿”å›
        unique_rpd_ids = list(set(rpd_ids))

        logger.info(
            f"Expanded {len(review_set_ids)} review sets to {len(unique_rpd_ids)} RPD IDs "
            f"for project {project_id}"
        )

        return unique_rpd_ids

    except Exception as e:
        logger.error(f"Failed to expand review sets to RPD IDs: {str(e)}")
        return []


async def batch_initiate_parallel(
    subtasks: List[Subtask],
    initiated_by_user_id: UUID,
    rpd_ids: Optional[List[UUID]] = None,
    review_set_ids: Optional[List[UUID]] = None,
    mode: AiReviewMode = AiReviewMode.QUALITY,
    max_concurrent: Optional[int] = None,
    batch_id: Optional[str] = None
) -> None:
    """
    å¹¶è¡Œå¤„ç†å¤šä¸ªå­ä»»åŠ¡çš„è‡ªå®šä¹‰AIå®¡æŸ¥ã€‚

    è¿™ä¸ªå‡½æ•°è®¾è®¡ä¸ºåå°ä»»åŠ¡ä½¿ç”¨ï¼Œæ‰€æœ‰ç»“æœé€šè¿‡æ—¥å¿—è®°å½•ã€‚
    ç”±äºæ˜¯åå°ä»»åŠ¡ï¼Œè¿”å›å€¼ä¼šè¢«FastAPIæ¡†æ¶ä¸¢å¼ƒã€‚

    Args:
        subtasks: éœ€è¦å¤„ç†çš„å­ä»»åŠ¡åˆ—è¡¨
        initiated_by_user_id: å‘èµ·ç”¨æˆ·çš„ID
        rpd_ids: å¯é€‰çš„RPD IDsåˆ—è¡¨ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨è¿™äº›RPD
        review_set_ids: å¯é€‰çš„Review Set IDsåˆ—è¡¨ï¼Œå°†è¢«å±•å¼€ä¸ºRPD IDs
        mode: AIå®¡æŸ¥æ¨¡å¼ï¼ˆquality/speedï¼‰
        max_concurrent: æœ€å¤§å¹¶å‘æ•°é‡ï¼Œé»˜è®¤ä» settings ä¸­è¯»å–
        batch_id: å¯é€‰çš„æ‰¹æ¬¡IDï¼Œå¦‚æœæ²¡æœ‰æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ

    Returns:
        None: åå°ä»»åŠ¡ä¸éœ€è¦è¿”å›å€¼ï¼Œæ‰€æœ‰ä¿¡æ¯é€šè¿‡æ—¥å¿—è¾“å‡º
    """

    batch_start_time = time.time()
    # ä½¿ç”¨ä¼ å…¥çš„batch_idï¼Œå¦‚æœæ²¡æœ‰åˆ™ç”Ÿæˆä¸€ä¸ª
    if not batch_id:
        batch_id = str(uuid.uuid4())[:8]

    # ========== æ•°æ®åº“è®°å½• - å¼€å§‹ ==========
    from datetime import datetime, timezone

    from aimage_supervision.enums import BatchJobStatus
    from aimage_supervision.models import BatchProcessJob, User

    # è·å–é¡¹ç›®IDï¼ˆä»ç¬¬ä¸€ä¸ªsubtaskè·å–ï¼Œå‡è®¾æ‰€æœ‰subtaskå±äºåŒä¸€ä¸ªé¡¹ç›®ï¼‰
    project_id = None
    if subtasks:
        first_subtask = subtasks[0]
        await first_subtask.fetch_related('task__project')
        project_id = first_subtask.task.project.id if first_subtask.task and first_subtask.task.project else None

    # å±•å¼€Review Setsåˆ°RPD IDs
    expanded_rpd_ids = []
    if review_set_ids and project_id:
        expanded_rpd_ids = await expand_review_sets_to_rpd_ids(project_id, review_set_ids)

    # åˆå¹¶æ‰€æœ‰RPD IDs
    final_rpd_ids = []
    if rpd_ids:
        final_rpd_ids.extend(rpd_ids)
    if expanded_rpd_ids:
        final_rpd_ids.extend(expanded_rpd_ids)

    # å»é‡
    final_rpd_ids = list(set(final_rpd_ids))

    # åˆ›å»ºæ‰¹å¤„ç†ä»»åŠ¡è®°å½•
    batch_job = await BatchProcessJob.create(
        batch_id=batch_id,
        job_name=f"AI_Review_{mode.value}_{batch_id}_{len(subtasks)}tasks",
        job_type="ai_review_custom",
        status=BatchJobStatus.RUNNING,
        created_by_id=initiated_by_user_id,
        project_id=project_id,
        total_items=len(subtasks),
        processed_items=0,
        successful_items=0,
        failed_items=0,
        started_at=datetime.now(timezone.utc),
        max_concurrent=max_concurrent if max_concurrent is not None else MAX_CONCURRENT,
        parameters={
            "subtask_ids": [str(subtask.id) for subtask in subtasks],
            "rpd_ids": [str(rpd_id) for rpd_id in final_rpd_ids] if final_rpd_ids else None,
            "review_set_ids": [str(rs_id) for rs_id in review_set_ids] if review_set_ids else None,
            "mode": mode.value,
            "max_concurrent": max_concurrent if max_concurrent is not None else MAX_CONCURRENT,
            "initiated_by_user_id": str(initiated_by_user_id)
        }
    )

    logger.info(f"ğŸ—„ï¸ [æ‰¹æ¬¡ {batch_id}] åˆ›å»ºæ•°æ®åº“è®°å½•: {batch_job.id}")

    # åˆ›å»ºä¿¡å·é‡æ¥æ§åˆ¶å¹¶å‘æ•°é‡
    if max_concurrent is None:
        max_concurrent = MAX_CONCURRENT
    semaphore = asyncio.Semaphore(max_concurrent)

    async def process_single_subtask_with_limit(subtask: Subtask, task_index: int) -> Dict[str, Any]:
        """å¸¦å¹¶å‘é™åˆ¶çš„å•ä¸ªå­ä»»åŠ¡å¤„ç†"""
        subtask_short_id = str(subtask.id)[:8]

        # ç­‰å¾…è·å–ä¿¡å·é‡çš„æ—¶é—´
        wait_start_time = time.time()

        async with semaphore:
            wait_time = time.time() - wait_start_time
            actual_start_time = time.time()
            try:
                result = await initiate_ai_review_for_subtask(
                    subtask_id=subtask.id,
                    initiated_by_user_id=initiated_by_user_id,
                    cr_check=False,  # æ™®é€šAIå®¡æŸ¥ï¼Œä¸æ˜¯CRæ£€æŸ¥
                    rpd_ids=final_rpd_ids,
                    mode=mode
                )

                processing_time = time.time() - actual_start_time
                total_time_from_batch_start = time.time() - batch_start_time
                # è®¡ç®—æ•´ä½“ä¸¥é‡ç¨‹åº¦
                overall_severity = "safe"  # é»˜è®¤å€¼
                if result.findings:
                    # è·å–æ‰€æœ‰findingsçš„severity
                    severities = [
                        finding.severity for finding in result.findings]
                    # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åºï¼šrisk > alert > safe
                    severity_order = {"risk": 3, "alert": 2, "safe": 1,
                                      # å‘åå…¼å®¹æ—§å€¼
                                      "high": 3, "medium": 2, "low": 1}
                    max_severity_value = max(
                        severities, key=lambda s: severity_order.get(s, 0))
                    overall_severity = max_severity_value
                return {
                    "subtask_id": str(subtask.id),
                    "subtask_short_id": subtask_short_id,
                    "task_index": task_index + 1,
                    "status": "success",
                    "ai_review_id": str(result.id),
                    "findings_count": len(result.findings) if result.findings else 0,
                    "severity": overall_severity,
                    "wait_time": wait_time,
                    "processing_time": processing_time,
                    "total_time_from_batch_start": total_time_from_batch_start,
                    "start_timestamp": actual_start_time,
                    "end_timestamp": time.time(),
                    "error": None
                }

            except Exception as e:
                processing_time = time.time() - actual_start_time
                total_time_from_batch_start = time.time() - batch_start_time
                error_msg = f"å¤„ç†å­ä»»åŠ¡ {subtask.id} æ—¶å‡ºé”™: {str(e)}"
                return {
                    "subtask_id": str(subtask.id),
                    "subtask_short_id": subtask_short_id,
                    "task_index": task_index + 1,
                    "status": "error",
                    "ai_review_id": None,
                    "findings_count": 0,
                    "severity": None,
                    "wait_time": wait_time,
                    "processing_time": processing_time,
                    "total_time_from_batch_start": total_time_from_batch_start,
                    "start_timestamp": actual_start_time,
                    "end_timestamp": time.time(),
                    "error": error_msg
                }

    tasks = [process_single_subtask_with_limit(
        subtask, i) for i, subtask in enumerate(subtasks)]

    # è®°å½•ä»»åŠ¡åˆ›å»ºå®Œæˆæ—¶é—´
    tasks_created_time = time.time()

    # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼Œä½¿ç”¨ return_exceptions=True ç¡®ä¿å•ä¸ªä»»åŠ¡å¤±è´¥ä¸å½±å“å…¶ä»–ä»»åŠ¡
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # è®°å½•æ‰€æœ‰ä»»åŠ¡å®Œæˆæ—¶é—´
    all_tasks_completed_time = time.time()

    # å¤„ç†å¯èƒ½çš„å¼‚å¸¸ç»“æœ
    processed_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            # å¦‚æœ gather æœ¬èº«å‡ºç°å¼‚å¸¸
            logger.error(f"ğŸ”¥ [æ‰¹æ¬¡ {batch_id}] ä»»åŠ¡ {i+1} gatherå¼‚å¸¸: {str(result)}")
            processed_results.append({
                "subtask_id": str(subtasks[i].id),
                "subtask_short_id": str(subtasks[i].id)[:8],
                "task_index": i + 1,
                "status": "error",
                "ai_review_id": None,
                "findings_count": 0,
                "severity": None,
                "wait_time": 0,
                "processing_time": 0,
                "total_time_from_batch_start": all_tasks_completed_time - batch_start_time,
                "start_timestamp": batch_start_time,
                "end_timestamp": all_tasks_completed_time,
                "error": f"æ‰¹é‡å¤„ç†å¼‚å¸¸: {str(result)}"
            })
        else:
            processed_results.append(result)  # type: ignore[arg-type]

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_time = all_tasks_completed_time - batch_start_time
    successful_count = sum(
        1 for r in processed_results if r["status"] == "success")
    failed_count = len(processed_results) - successful_count

    # åˆ›å»º subtask_id åˆ° severity çš„æ˜ å°„å­—å…¸
    subtask_severity_map = {}
    for result in processed_results:
        if result["status"] == "success" and result["severity"]:
            subtask_severity_map[str(result["subtask_id"])
                                 ] = result["severity"]
        else:
            subtask_severity_map[str(result["subtask_id"])] = "failed"

    # è®¡ç®—å¹¶è¡Œæ•ˆç‡
    if successful_count > 0:
        avg_processing_time = sum(r["processing_time"] for r in processed_results if r["status"]
                                  == "success") / successful_count
        theoretical_serial_time = avg_processing_time * len(subtasks)
        parallel_efficiency = (theoretical_serial_time /
                               total_time) * 100 if total_time > 0 else 0

    # ========== æ•°æ®åº“è®°å½• - ç»“æŸ ==========
    try:
        # æ›´æ–°æ‰¹å¤„ç†ä»»åŠ¡è®°å½•
        if successful_count == 0 and failed_count > 0:
            # å…¨éƒ¨å¤±è´¥
            batch_job.status = BatchJobStatus.FAILED
        else:
            # æœ‰æˆåŠŸçš„ä»»åŠ¡ï¼ˆå¯èƒ½ä¹Ÿæœ‰å¤±è´¥çš„ï¼‰
            batch_job.status = BatchJobStatus.COMPLETED
        batch_job.processed_items = len(processed_results)
        batch_job.successful_items = successful_count
        batch_job.failed_items = failed_count
        batch_job.completed_at = datetime.now(timezone.utc)

        # ä¿å­˜è¯¦ç»†ç»“æœ
        batch_job.results = {
            "summary": {
                "total_tasks": len(subtasks),
                "successful_count": successful_count,
                "failed_count": failed_count,
                "total_time_seconds": total_time,
                "parallel_efficiency_percent": parallel_efficiency if successful_count > 0 else 0,
                "avg_processing_time_seconds": avg_processing_time if successful_count > 0 else 0,
                "severity_counts": subtask_severity_map,
                "mode": mode.value,
                "rpd_count": len(final_rpd_ids) if final_rpd_ids else 0,
                "review_set_count": len(review_set_ids) if review_set_ids else 0
            },
            "performance_metrics": {
                "batch_start_time": batch_start_time,
                "tasks_created_time": tasks_created_time,
                "all_tasks_completed_time": all_tasks_completed_time,
                "theoretical_serial_time": theoretical_serial_time if successful_count > 0 else 0
            }
        }

        await batch_job.save()

        logger.info(
            f"ğŸ—„ï¸ [æ‰¹æ¬¡ {batch_id}] æ›´æ–°æ•°æ®åº“è®°å½•å®Œæˆ: çŠ¶æ€={batch_job.status.value}, æˆåŠŸ={successful_count}/{len(subtasks)}")

    except Exception as db_error:
        logger.error(f"ğŸ—„ï¸ [æ‰¹æ¬¡ {batch_id}] æ›´æ–°æ•°æ®åº“è®°å½•å¤±è´¥: {str(db_error)}")
        # å³ä½¿æ•°æ®åº“æ›´æ–°å¤±è´¥ï¼Œä¹Ÿä¸å½±å“ä¸»è¦ä»»åŠ¡çš„å®Œæˆ
